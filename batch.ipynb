{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다수의 SQL 파일을 실행하는 스크립트(Postgresql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "\n",
    "def execute_sql_file(conn, file_path):\n",
    "    \"\"\"SQL 파일을 한 줄씩 읽어 쿼리 단위(세미콜론 기준)로 실행하는 함수\"\"\"\n",
    "    print(f\"{file_path} 파일을 실행합니다.\")\n",
    "    query_buffer = \"\"\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            query_buffer += line\n",
    "            # 세미콜론이 포함된 경우 쿼리 단위로 분리\n",
    "            if ';' in line:\n",
    "                queries = query_buffer.split(';')\n",
    "                # 마지막 쿼리는 미완성일 수 있으므로 제외하고 실행\n",
    "                for query in queries[:-1]:\n",
    "                    if query.strip():\n",
    "                        with conn.cursor() as cursor:\n",
    "                            cursor.execute(query)\n",
    "                        conn.commit()\n",
    "                # 미완성 쿼리를 버퍼에 남김\n",
    "                query_buffer = queries[-1]\n",
    "    \n",
    "    # 파일 종료 후 남은 쿼리가 있다면 실행\n",
    "    if query_buffer.strip():\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(query_buffer)\n",
    "        conn.commit()\n",
    "    \n",
    "    print(f\"{file_path} 파일 실행이 완료되었습니다.\")\n",
    "\n",
    "def execute_sql_files_in_directory(db_config, directory):\n",
    "    \"\"\"디렉토리 내 모든 SQL 파일을 순차적으로 실행하는 함수\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # PostgreSQL 연결\n",
    "        conn = psycopg2.connect(**db_config)\n",
    "        print(\"Connected to PostgreSQL\")\n",
    "        \n",
    "        # 디렉토리 내 SQL 파일 실행 (파일 이름 순 정렬)\n",
    "        for file in sorted(os.listdir(directory)):\n",
    "            if file.endswith(\".sql\"):\n",
    "                execute_sql_file(conn, os.path.join(directory, file))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(\"Connection closed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # PostgreSQL 접속 정보\n",
    "    db_config = {\n",
    "        \"dbname\": \"DB 이름\",\n",
    "        \"user\": \"사용자\",\n",
    "        \"password\": \"비밀번호\",\n",
    "        \"host\": \"DB IP\",\n",
    "        \"port\": \"DB 포트\"\n",
    "    }\n",
    "    \n",
    "    # 실행할 SQL 파일이 있는 디렉토리 경로\n",
    "    sql_directory = \"디렉토리\"\n",
    "    \n",
    "    execute_sql_files_in_directory(db_config, sql_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다수의 CSV파일을 DB에 적재하는 스크립트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "schema = \"스키마\"\n",
    "\n",
    "def insert_csv_to_db(conn, csv_file_path, table_name, chunk_size=10000):\n",
    "    \"\"\"\n",
    "    대용량 CSV 파일을 chunk 단위로 PostgreSQL에 삽입하는 함수.\n",
    "    \n",
    "    Parameters:\n",
    "        conn: psycopg2 연결 객체\n",
    "        csv_file_path (str): CSV 파일 경로\n",
    "        table_name (str): 대상 테이블 이름\n",
    "        chunk_size (int): 한 번에 insert할 행 수 (기본: 10,000)\n",
    "    \"\"\"\n",
    "    print(f\"파일 {csv_file_path} → 테이블 {table_name} 삽입 시작 (Chunk size: {chunk_size})\")\n",
    "\n",
    "    # CSV 읽기 설정\n",
    "    read_options = {\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"sep\": \",\",  # 컬럼 구분자\n",
    "        \"quotechar\": '\"',  # 따옴표 문자\n",
    "        \"escapechar\": \"\\\\\",  # 이스케이프 문자\n",
    "        \"parse_dates\": True,  # 날짜 자동 변환\n",
    "        \"keep_default_na\": False,  # 빈 문자열을 NULL로 변환하지 않음\n",
    "        \"dtype\": str,  # 모든 컬럼을 문자열로 로드 후 변환\n",
    "        \"chunksize\": chunk_size\n",
    "    }\n",
    "\n",
    "    # Chunk 단위로 읽어 DB 삽입\n",
    "    for chunk in pd.read_csv(csv_file_path, **read_options):\n",
    "        if chunk.empty:\n",
    "            print(f\"파일 {csv_file_path} 에 데이터가 없어 스킵합니다.\")\n",
    "            return\n",
    "\n",
    "        # 빈 문자열(\"\")을 None (NULL)로 변환\n",
    "        chunk = chunk.applymap(lambda x: None if x == \"\" else x)\n",
    "\n",
    "        # 컬럼명 매칭\n",
    "        columns = list(chunk.columns)\n",
    "        chunk = chunk.where(pd.notna(chunk), None)  # NaN -> None 변환\n",
    "\n",
    "        # 문자열 길이 초과 방지 (50자로 제한)\n",
    "        for col in chunk.columns:\n",
    "            chunk[col] = chunk[col].apply(lambda x: x[:50] if isinstance(x, str) else x)\n",
    "\n",
    "        values = [tuple(row) for row in chunk.to_numpy()]\n",
    "\n",
    "        # INSERT 쿼리 (중복된 경우 건너뛰기)\n",
    "        cols_str = ', '.join(columns)\n",
    "        query = f\"\"\"\n",
    "        INSERT INTO {table_name} ({cols_str}) \n",
    "        VALUES %s \n",
    "        \"\"\"  # 중복 키는 무시하고 삽입하지 않음\n",
    "\n",
    "        # PostgreSQL에 데이터 삽입\n",
    "        with conn.cursor() as cur:\n",
    "            execute_values(cur, query, values)\n",
    "        conn.commit()\n",
    "        \n",
    "        print(f\"{csv_file_path} → {len(values)}건 삽입 완료.\")\n",
    "\n",
    "def process_csv_files_in_directory(db_config, directory, chunk_size=10000):\n",
    "    \"\"\"\n",
    "    지정된 디렉토리 내의 모든 CSV 파일을 PostgreSQL에 삽입하는 함수.\n",
    "    \n",
    "    파일명 형식: 테이블명_날짜.csv\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # PostgreSQL 연결\n",
    "        conn = psycopg2.connect(**db_config)\n",
    "        print(\"PostgreSQL 연결 성공\")\n",
    "\n",
    "        # 디렉토리 내 모든 CSV 파일 처리\n",
    "        for filename in sorted(os.listdir(directory)):\n",
    "            if filename.lower().endswith(('.csv', '.tsv', '.txt')):\n",
    "                # 정규식으로 테이블명 추출 (테이블명_날짜.csv 형식)\n",
    "                match = re.match(r\"^([A-Za-z_\\d]+)_(\\d{8,14})\\.(csv|tsv|txt)$\", filename)\n",
    "\n",
    "                if match:\n",
    "                    table_name = re.sub(r'\\d', '', match.group(1))\n",
    "                    table_name = schema+table_name\n",
    "                    file_path = os.path.join(directory, filename)\n",
    "                    insert_csv_to_db(conn, file_path, table_name, chunk_size=chunk_size)\n",
    "                else:\n",
    "                    print(f\"파일 {filename} 은 형식이 맞지 않아 스킵됩니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(\"DB 연결 종료\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # PostgreSQL 접속 정보\n",
    "    db_config = {\n",
    "        \"dbname\": \"DB 이름\",\n",
    "        \"user\": \"사용자\",\n",
    "        \"password\": \"비밀번호\",\n",
    "        \"host\": \"DB IP\",\n",
    "        \"port\": \"DB 포트\"\n",
    "    }\n",
    "\n",
    "    # CSV 파일이 있는 디렉토리\n",
    "    csv_directory = \"디렉토리\"\n",
    "\n",
    "    # CSV 파일을 PostgreSQL에 삽입\n",
    "    process_csv_files_in_directory(db_config, csv_directory, chunk_size=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
